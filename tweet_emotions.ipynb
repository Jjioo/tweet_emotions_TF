{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsjStGuxtEPp"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from keras.callbacks import ProgbarLogger\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "metadata": {
        "id": "GWfPyJflwIJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"tweet_emotions.csv\")\n",
        "df.columns"
      ],
      "metadata": {
        "id": "85AGB0kjFFjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.reindex(columns=['tweet_id', 'content', 'sentiment'])"
      ],
      "metadata": {
        "id": "bj4Uc393yIkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,1].values.reshape(-1, 1)\n",
        "y = df.iloc[:,-1].values\n",
        "over = RandomOverSampler()\n",
        "X, y = over.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "f3DC4PWzxuD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a label encoder object\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Perform label encoding on y\n",
        "y_encoded = label_encoder.fit_transform(y) + 1\n",
        "\n",
        "# Reshape 'content' array to be 1-dimensional\n",
        "X_reshaped = X.reshape(-1)\n",
        "\n",
        "# Create a new DataFrame with 'sentiment' and 'content' columns\n",
        "df = pd.DataFrame({'content': X_reshaped,'sentiment': y_encoded})"
      ],
      "metadata": {
        "id": "ku-aeWyBx0bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Sc-HIP15x2oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#improve the model's performance:\n",
        "1- Increase the model's capacity\n",
        "\n",
        "2- Increase the model's capacity\n",
        "\n",
        "3- Use a different optimizer\n",
        "\n",
        "4- Increase the number of training epochs\n",
        "\n",
        "5- Perform data preprocessing\n",
        "\n",
        "6- Perform data preprocessing\n",
        "\n",
        "7- Perform data preprocessing\n"
      ],
      "metadata": {
        "id": "pssEEH4suSms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "df['content'] = df['content'].astype(str)  # Convert the 'content' column to string type\n",
        "df['content'].fillna('', inplace=True)  # Fill missing values with empty strings\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['content'])\n",
        "sequences = tokenizer.texts_to_sequences(df['content'])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Pad the sequences to have the same length\n",
        "max_length = 100  # adjust as needed\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length)\n",
        "\n",
        "# Convert sentiment to one-hot encoded vectors\n",
        "sentiment_vectors = tf.keras.utils.to_categorical(df['sentiment'])\n",
        "num_classes = len(sentiment_vectors[0])\n",
        "\n",
        "# Create the input and output data for the model\n",
        "X = padded_sequences\n",
        "y = sentiment_vectors\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train_size = int(0.8 * len(X))\n",
        "train_X, test_X = X[:train_size], X[train_size:]\n",
        "train_y, test_y = y[:train_size], y[train_size:]\n",
        "\n",
        "# Specify the dimensionality of the embedding\n",
        "embedding_dim = 100\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model with RMSprop optimizer\n",
        "optimizer = RMSprop(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_X, test_y)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "id": "T7VfMv463qsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(train_X, train_y, epochs=20, batch_size=64, validation_data=(test_X, test_y))"
      ],
      "metadata": {
        "id": "j63NhzLHZOnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_accuracy = round(history.history['accuracy'][-1], 2)\n",
        "last_loss = round(history.history['loss'][-1], 2)\n",
        "val_accuracy = round(history.history['val_accuracy'][-1], 2)\n",
        "\n",
        "\n",
        "print(\"Last Loss:\", last_loss)\n",
        "print(\"Validation Accuracy:\", val_accuracy)\n",
        "print(\"Last Accuracy:\", last_accuracy)"
      ],
      "metadata": {
        "id": "p0_w6pLpQWQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the input text\n",
        "input_text = \"Layin n bed with a headache  ughhhh...waitin on your call...\"\n",
        "input_sequence = tokenizer.texts_to_sequences([input_text])\n",
        "input_sequence = pad_sequences(input_sequence, maxlen=max_length)\n",
        "# Get the model's prediction\n",
        "prediction = model.predict(input_sequence)\n",
        "sentiment_labels =['anger','boredom','empty','enthusiasm','fun','happiness','hate','love','neutral','relief','sadness','surprise','worry']\n",
        "predicted_sentiment = sentiment_labels[np.argmax(prediction)]\n",
        "# Print the output\n",
        "print(\"Input Text:\", input_text)\n",
        "print(\"Predicted Sentiment:\", predicted_sentiment)\n"
      ],
      "metadata": {
        "id": "bLii52PVo4vB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MIK5y-6xo61A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['content'])\n",
        "sequences = tokenizer.texts_to_sequences(df['content'])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Pad the sequences to have the same length\n",
        "max_length = 100  # adjust as needed\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length)\n",
        "\n",
        "# Convert sentiment to one-hot encoded vectors\n",
        "sentiment_vectors = tf.keras.utils.to_categorical(df['sentiment'])\n",
        "num_classes = len(sentiment_vectors[0])\n",
        "\n",
        "# Create the input and output data for the model\n",
        "X = padded_sequences\n",
        "y = sentiment_vectors\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train_size = int(0.8 * len(X))\n",
        "train_X, test_X = X[:train_size], X[train_size:]\n",
        "train_y, test_y = y[:train_size], y[train_size:]\n",
        "\n",
        "# Specify the dimensionality of the embedding\n",
        "embedding_dim = 100\n",
        "\n",
        "# Define the model\n",
        "T_model = tf.keras.Sequential()\n",
        "T_model.add(tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
        "T_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)))\n",
        "T_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))\n",
        "T_model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "T_model.add(tf.keras.layers.Dropout(0.4))\n",
        "T_model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model with RMSprop optimizer\n",
        "optimizer = RMSprop(learning_rate=0.001)\n",
        "T_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "6c0Vc4f-a3ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the number of epochs and batch size for training\n",
        "epochs = 20\n",
        "batch_size = 32\n",
        "\n",
        "# Fit the model to the training data\n",
        "T_model.fit(train_X, train_y, epochs=epochs, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "pmZrp5L_gCUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = T_model.evaluate(test_X, test_y, verbose=0)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "id": "ju7i5M2dlkc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the input text\n",
        "input_text = \"Layin n bed with a headache  ughhhh...waitin on your call...\"\n",
        "input_sequence = tokenizer.texts_to_sequences([input_text])\n",
        "input_sequence = pad_sequences(input_sequence, maxlen=max_length)\n",
        "# Get the model's prediction\n",
        "prediction = T_model.predict(input_sequence)\n",
        "sentiment_labels =['anger','boredom','empty','enthusiasm','fun','happiness','hate','love','neutral','relief','sadness','surprise','worry']\n",
        "predicted_sentiment = sentiment_labels[np.argmax(prediction)]\n",
        "# Print the output\n",
        "print(\"Input Text:\", input_text)\n",
        "print(\"Predicted Sentiment:\", predicted_sentiment)\n"
      ],
      "metadata": {
        "id": "LMtS4pkGo-TB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}